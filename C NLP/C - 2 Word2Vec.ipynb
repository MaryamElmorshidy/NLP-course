{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Notebook\n",
    "\n",
    "#https://www.kaggle.com/alincijov/continuous-bag-of-words-cbow-numpy-for-beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP 4.4.4 Word2Vec       i don't understand this lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are about to study the idea of a computational process Computational processes are abstract beings that inhabit computers As they evolve processes manipulate other abstract things called data The evolution of a process is directed by a pattern of rules called a program People create programs to direct processes In effect we conjure the spirits of the computer with our spells '"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re .sub (\"[^A-Za-z0-9]+\",\" \", sentences)  # sub for replace\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are about to study the idea of computational process Computational processes are abstract beings that inhabit computers As they evolve processes manipulate other abstract things called data The evolution of process is directed by pattern of rules called program People create programs to direct processes In effect we conjure the spirits of the computer with our spells'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But Why this ?????\n",
    "\n",
    "sentences = re .sub (r\"(?:^| )\\w(?:$| )\", \" \",  sentences ).strip()\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=sentences.lower()\n",
    "words=sentences.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'computational', 'process', 'computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers', 'as', 'they', 'evolve', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data', 'the', 'evolution', 'of', 'process', 'is', 'directed', 'by', 'pattern', 'of', 'rules', 'called', 'program', 'people', 'create', 'programs', 'to', 'direct', 'processes', 'in', 'effect', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'create', 'evolution', 'things', 'the', 'beings', 'inhabit', 'rules', 'processes', 'idea', 'they', 'called', 'as', 'computational', 'to', 'conjure', 'program', 'is', 'abstract', 'our', 'of', 'study', 'about', 'direct', 'programs', 'spells', 'process', 'computers', 'manipulate', 'data', 'are', 'computer', 'directed', 'with', 'that', 'other', 'by', 'people', 'spirits', 'in', 'pattern', 'we', 'effect', 'evolve'}\n"
     ]
    }
   ],
   "source": [
    "vocab = set(words)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "embed_dim=10\n",
    "context_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'create': 0, 'evolution': 1, 'things': 2, 'the': 3, 'beings': 4, 'inhabit': 5, 'rules': 6, 'processes': 7, 'idea': 8, 'they': 9, 'called': 10, 'as': 11, 'computational': 12, 'to': 13, 'conjure': 14, 'program': 15, 'is': 16, 'abstract': 17, 'our': 18, 'of': 19, 'study': 20, 'about': 21, 'direct': 22, 'programs': 23, 'spells': 24, 'process': 25, 'computers': 26, 'manipulate': 27, 'data': 28, 'are': 29, 'computer': 30, 'directed': 31, 'with': 32, 'that': 33, 'other': 34, 'by': 35, 'people': 36, 'spirits': 37, 'in': 38, 'pattern': 39, 'we': 40, 'effect': 41, 'evolve': 42}\n"
     ]
    }
   ],
   "source": [
    "word_index={word: i for i ,word in enumerate(vocab)}\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'create', 1: 'evolution', 2: 'things', 3: 'the', 4: 'beings', 5: 'inhabit', 6: 'rules', 7: 'processes', 8: 'idea', 9: 'they', 10: 'called', 11: 'as', 12: 'computational', 13: 'to', 14: 'conjure', 15: 'program', 16: 'is', 17: 'abstract', 18: 'our', 19: 'of', 20: 'study', 21: 'about', 22: 'direct', 23: 'programs', 24: 'spells', 25: 'process', 26: 'computers', 27: 'manipulate', 28: 'data', 29: 'are', 30: 'computer', 31: 'directed', 32: 'with', 33: 'that', 34: 'other', 35: 'by', 36: 'people', 37: 'spirits', 38: 'in', 39: 'pattern', 40: 'we', 41: 'effect', 42: 'evolve'}\n"
     ]
    }
   ],
   "source": [
    "index_word={i:word for i ,word in enumerate(vocab)}\n",
    "print(index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['we', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'computational'], 'idea'), (['the', 'idea', 'computational', 'process'], 'of'), (['idea', 'of', 'process', 'computational'], 'computational'), (['of', 'computational', 'computational', 'processes'], 'process'), (['computational', 'process', 'processes', 'are'], 'computational'), (['process', 'computational', 'are', 'abstract'], 'processes'), (['computational', 'processes', 'abstract', 'beings'], 'are'), (['processes', 'are', 'beings', 'that'], 'abstract'), (['are', 'abstract', 'that', 'inhabit'], 'beings'), (['abstract', 'beings', 'inhabit', 'computers'], 'that'), (['beings', 'that', 'computers', 'as'], 'inhabit'), (['that', 'inhabit', 'as', 'they'], 'computers'), (['inhabit', 'computers', 'they', 'evolve'], 'as'), (['computers', 'as', 'evolve', 'processes'], 'they'), (['as', 'they', 'processes', 'manipulate'], 'evolve'), (['they', 'evolve', 'manipulate', 'other'], 'processes'), (['evolve', 'processes', 'other', 'abstract'], 'manipulate'), (['processes', 'manipulate', 'abstract', 'things'], 'other'), (['manipulate', 'other', 'things', 'called'], 'abstract'), (['other', 'abstract', 'called', 'data'], 'things'), (['abstract', 'things', 'data', 'the'], 'called'), (['things', 'called', 'the', 'evolution'], 'data'), (['called', 'data', 'evolution', 'of'], 'the'), (['data', 'the', 'of', 'process'], 'evolution'), (['the', 'evolution', 'process', 'is'], 'of'), (['evolution', 'of', 'is', 'directed'], 'process'), (['of', 'process', 'directed', 'by'], 'is'), (['process', 'is', 'by', 'pattern'], 'directed'), (['is', 'directed', 'pattern', 'of'], 'by'), (['directed', 'by', 'of', 'rules'], 'pattern'), (['by', 'pattern', 'rules', 'called'], 'of'), (['pattern', 'of', 'called', 'program'], 'rules'), (['of', 'rules', 'program', 'people'], 'called'), (['rules', 'called', 'people', 'create'], 'program'), (['called', 'program', 'create', 'programs'], 'people'), (['program', 'people', 'programs', 'to'], 'create'), (['people', 'create', 'to', 'direct'], 'programs'), (['create', 'programs', 'direct', 'processes'], 'to'), (['programs', 'to', 'processes', 'in'], 'direct'), (['to', 'direct', 'in', 'effect'], 'processes'), (['direct', 'processes', 'effect', 'we'], 'in'), (['processes', 'in', 'we', 'conjure'], 'effect'), (['in', 'effect', 'conjure', 'the'], 'we'), (['effect', 'we', 'the', 'spirits'], 'conjure'), (['we', 'conjure', 'spirits', 'of'], 'the'), (['conjure', 'the', 'of', 'the'], 'spirits'), (['the', 'spirits', 'the', 'computer'], 'of'), (['spirits', 'of', 'computer', 'with'], 'the'), (['of', 'the', 'with', 'our'], 'computer'), (['the', 'computer', 'our', 'spells'], 'with')]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "for i in range (2,len(words)-2):\n",
    "    context=[words[i-2],words[i-1],words[i+1],words[i+2]]\n",
    "    target=words[i]\n",
    "    data.append((context,target))\n",
    "    \n",
    "print(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 10)\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.random.random_sample((vocab_size,embed_dim))\n",
    "print(embeddings.shape)\n",
    "#print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear (m,theta):\n",
    "    w=theta\n",
    "    return m.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??????????????????????????\n",
    "def log_softmax(x):\n",
    "    e_x= np.exp(x-np.max(x))\n",
    "    return np.log(e_x/e_x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??????????????????????????\n",
    "def NLLLoss(logs , targets):\n",
    "    out = logs [range(len(targets)),targets]\n",
    "    return -out . sum()/len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??????????????????????????\n",
    "def log_softmax_crossentropy_with_logits(logits,target):\n",
    "    out =np.zeros_like(logits)\n",
    "    out[np.arange (len(logits)),target]=1\n",
    "    softmax = np.exp(logits)/np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "    return (-out+softmax)/logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward (context_id, w):\n",
    "    m = embeddings[context_id].reshape(1,-1)\n",
    "    n= linear(m,w)\n",
    "    o= log_softmax(n)\n",
    "    return m , n ,o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(p , w , target_id):\n",
    "    m , n ,o =p\n",
    "    dlog= log_softmax_crossentropy_with_logits(n,target_id)\n",
    "    dw = m .T.dot (dlog)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize ( w, grad , lr=0.03):\n",
    "    w -=grad*lr\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta= np.random.uniform(-1,1,(2*context_size*embed_dim , vocab_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses={}\n",
    "for epoch in range(80):\n",
    "    losses=[]\n",
    "    for context, target in data:\n",
    "        context_idx= np.array ([word_index[w] for w in context ])\n",
    "        pred = forward(context_idx,theta)\n",
    "        \n",
    "        target_idx=np.array([word_index[target]])\n",
    "        loss = NLLLoss(pred[-1], target_idx)\n",
    "        losses.append(loss)\n",
    "        grad=backward(pred,theta,target_idx)\n",
    "        theta=optimize(theta,grad, lr=0.03)\n",
    "        \n",
    "    epoch_losses[epoch]=losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Losses')"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ix = np.arange(0,80)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Epoch/Losses', fontsize=20)\n",
    "plt.plot(ix,[epoch_losses[i][0] for i in ix])\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Losses', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   -------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source :\n",
    "\n",
    "#https://www.geeksforgeeks.org/implement-your-own-word2vecskip-gram-model-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def softmax(x):\n",
    "\t\"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "\te_x = np.exp(x - np.max(x))\n",
    "\treturn e_x / e_x.sum()\n",
    "\n",
    "class word2vec(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.N = 10\n",
    "\t\tself.X_train = []\n",
    "\t\tself.y_train = []\n",
    "\t\tself.window_size = 2\n",
    "\t\tself.alpha = 0.001\n",
    "\t\tself.words = []\n",
    "\t\tself.word_index = {}\n",
    "\n",
    "\tdef initialize(self,V,data):\n",
    "\t\tself.V = V\n",
    "\t\tself.W = np.random.uniform(-0.8, 0.8, (self.V, self.N))\n",
    "\t\tself.W1 = np.random.uniform(-0.8, 0.8, (self.N, self.V))\n",
    "\t\t\n",
    "\t\tself.words = data\n",
    "\t\tfor i in range(len(data)):\n",
    "\t\t\tself.word_index[data[i]] = i\n",
    "\n",
    "\t\n",
    "\tdef feed_forward(self,X):\n",
    "\t\tself.h = np.dot(self.W.T,X).reshape(self.N,1)\n",
    "\t\tself.u = np.dot(self.W1.T,self.h)\n",
    "\t\t#print(self.u)\n",
    "\t\tself.y = softmax(self.u)\n",
    "\t\treturn self.y\n",
    "\t\t\n",
    "\tdef backpropagate(self,x,t):\n",
    "\t\te = self.y - np.asarray(t).reshape(self.V,1)\n",
    "\t\t# e.shape is V x 1\n",
    "\t\tdLdW1 = np.dot(self.h,e.T)\n",
    "\t\tX = np.array(x).reshape(self.V,1)\n",
    "\t\tdLdW = np.dot(X, np.dot(self.W1,e).T)\n",
    "\t\tself.W1 = self.W1 - self.alpha*dLdW1\n",
    "\t\tself.W = self.W - self.alpha*dLdW\n",
    "\t\t\n",
    "\tdef train(self,epochs):\n",
    "\t\tfor x in range(1,epochs):\t\n",
    "\t\t\tself.loss = 0\n",
    "\t\t\tfor j in range(len(self.X_train)):\n",
    "\t\t\t\tself.feed_forward(self.X_train[j])\n",
    "\t\t\t\tself.backpropagate(self.X_train[j],self.y_train[j])\n",
    "\t\t\t\tC = 0\n",
    "\t\t\t\tfor m in range(self.V):\n",
    "\t\t\t\t\tif(self.y_train[j][m]):\n",
    "\t\t\t\t\t\tself.loss += -1*self.u[m][0]\n",
    "\t\t\t\t\t\tC += 1\n",
    "\t\t\t\tself.loss += C*np.log(np.sum(np.exp(self.u)))\n",
    "\t\t\tprint(\"epoch \",x, \" loss = \",self.loss)\n",
    "\t\t\tself.alpha *= 1/( (1+self.alpha*x) )\n",
    "\t\t\t\n",
    "\tdef predict(self,word,number_of_predictions):\n",
    "\t\tif word in self.words:\n",
    "\t\t\tindex = self.word_index[word]\n",
    "\t\t\tX = [0 for i in range(self.V)]\n",
    "\t\t\tX[index] = 1\n",
    "\t\t\tprediction = self.feed_forward(X)\n",
    "\t\t\toutput = {}\n",
    "\t\t\tfor i in range(self.V):\n",
    "\t\t\t\toutput[prediction[i][0]] = i\n",
    "\t\t\t\n",
    "\t\t\ttop_context_words = []\n",
    "\t\t\tfor k in sorted(output,reverse=True):\n",
    "\t\t\t\ttop_context_words.append(self.words[output[k]])\n",
    "\t\t\t\tif(len(top_context_words)>=number_of_predictions):\n",
    "\t\t\t\t\tbreak\n",
    "\t\n",
    "\t\t\treturn top_context_words\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Word not found in dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus):\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttraining_data = []\n",
    "\tsentences = corpus.split(\".\")\n",
    "\tfor i in range(len(sentences)):\n",
    "\t\tsentences[i] = sentences[i].strip()\n",
    "\t\tsentence = sentences[i].split()\n",
    "\t\tx = [word.strip(string.punctuation) for word in sentence\n",
    "\t\t\t\t\t\t\t\t\tif word not in stop_words]\n",
    "\t\tx = [word.lower() for word in x]\n",
    "\t\ttraining_data.append(x)\n",
    "\treturn training_data\n",
    "\t\n",
    "\n",
    "def prepare_data_for_training(sentences,w2v):\n",
    "\tdata = {}\n",
    "\tfor sentence in sentences:\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tif word not in data:\n",
    "\t\t\t\tdata[word] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata[word] += 1\n",
    "\tV = len(data)\n",
    "\tdata = sorted(list(data.keys()))\n",
    "\tvocab = {}\n",
    "\tfor i in range(len(data)):\n",
    "\t\tvocab[data[i]] = i\n",
    "\t\n",
    "\t#for i in range(len(words)):\n",
    "\tfor sentence in sentences:\n",
    "\t\tfor i in range(len(sentence)):\n",
    "\t\t\tcenter_word = [0 for x in range(V)]\n",
    "\t\t\tcenter_word[vocab[sentence[i]]] = 1\n",
    "\t\t\tcontext = [0 for x in range(V)]\n",
    "\t\t\t\n",
    "\t\t\tfor j in range(i-w2v.window_size,i+w2v.window_size):\n",
    "\t\t\t\tif i!=j and j>=0 and j<len(sentence):\n",
    "\t\t\t\t\tcontext[vocab[sentence[j]]] += 1\n",
    "\t\t\tw2v.X_train.append(center_word)\n",
    "\t\t\tw2v.y_train.append(context)\n",
    "\tw2v.initialize(V,data)\n",
    "\n",
    "\treturn w2v.X_train,w2v.y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  loss =  46.1948787631058\n",
      "epoch  2  loss =  46.08300801591282\n",
      "epoch  3  loss =  45.972238960786356\n",
      "epoch  4  loss =  45.862664025887035\n",
      "epoch  5  loss =  45.75437081538204\n",
      "epoch  6  loss =  45.64744169872759\n",
      "epoch  7  loss =  45.54195345979221\n",
      "epoch  8  loss =  45.43797700904028\n",
      "epoch  9  loss =  45.33557716062558\n",
      "epoch  10  loss =  45.23481247488541\n",
      "epoch  11  loss =  45.135735165425636\n",
      "epoch  12  loss =  45.03839106877932\n",
      "epoch  13  loss =  44.942819673548264\n",
      "epoch  14  loss =  44.84905420501382\n",
      "epoch  15  loss =  44.75712176045508\n",
      "epoch  16  loss =  44.66704348984315\n",
      "epoch  17  loss =  44.578834816191886\n",
      "epoch  18  loss =  44.49250568963123\n",
      "epoch  19  loss =  44.40806086921748\n",
      "epoch  20  loss =  44.325500226586655\n",
      "epoch  21  loss =  44.24481906577572\n",
      "epoch  22  loss =  44.166008453855824\n",
      "epoch  23  loss =  44.08905555742316\n",
      "epoch  24  loss =  44.01394398045171\n",
      "epoch  25  loss =  43.94065409950845\n",
      "epoch  26  loss =  43.86916339284727\n",
      "epoch  27  loss =  43.79944676041504\n",
      "epoch  28  loss =  43.731476832308715\n",
      "epoch  29  loss =  43.66522426370689\n",
      "epoch  30  loss =  43.600658014749584\n",
      "epoch  31  loss =  43.53774561425651\n",
      "epoch  32  loss =  43.47645340654708\n",
      "epoch  33  loss =  43.41674678095606\n",
      "epoch  34  loss =  43.35859038392696\n",
      "epoch  35  loss =  43.30194831380937\n",
      "epoch  36  loss =  43.2467842986913\n",
      "epoch  37  loss =  43.193061857764306\n",
      "epoch  38  loss =  43.14074444685048\n",
      "epoch  39  loss =  43.08979558882159\n",
      "epoch  40  loss =  43.04017898971314\n",
      "epoch  41  loss =  42.991858641384596\n",
      "epoch  42  loss =  42.944798911605744\n",
      "epoch  43  loss =  42.89896462245831\n",
      "epoch  44  loss =  42.85432111793916\n",
      "epoch  45  loss =  42.81083432163439\n",
      "epoch  46  loss =  42.76847078530921\n",
      "epoch  47  loss =  42.72719772922545\n",
      "epoch  48  loss =  42.68698307496113\n",
      "epoch  49  loss =  42.64779547146498\n",
      "epoch  50  loss =  42.6096043150349\n",
      "epoch  51  loss =  42.572379763864134\n",
      "epoch  52  loss =  42.536092747753955\n",
      "epoch  53  loss =  42.50071497354635\n",
      "epoch  54  loss =  42.46621892678639\n",
      "epoch  55  loss =  42.432577870081566\n",
      "epoch  56  loss =  42.39976583858485\n",
      "epoch  57  loss =  42.36775763298921\n",
      "epoch  58  loss =  42.33652881038572\n",
      "epoch  59  loss =  42.30605567330238\n",
      "epoch  60  loss =  42.27631525720968\n",
      "epoch  61  loss =  42.24728531674922\n",
      "epoch  62  loss =  42.21894431091431\n",
      "epoch  63  loss =  42.19127138738678\n",
      "epoch  64  loss =  42.16424636621106\n",
      "epoch  65  loss =  42.13784972296552\n",
      "epoch  66  loss =  42.11206257157273\n",
      "epoch  67  loss =  42.0868666468719\n",
      "epoch  68  loss =  42.06224428706209\n",
      "epoch  69  loss =  42.03817841611026\n",
      "epoch  70  loss =  42.01465252620544\n",
      "epoch  71  loss =  41.99165066032938\n",
      "epoch  72  loss =  41.96915739500309\n",
      "epoch  73  loss =  41.947157823260596\n",
      "epoch  74  loss =  41.92563753789209\n",
      "epoch  75  loss =  41.9045826149923\n",
      "epoch  76  loss =  41.883979597843016\n",
      "epoch  77  loss =  41.86381548115325\n",
      "epoch  78  loss =  41.84407769567567\n",
      "epoch  79  loss =  41.824754093213514\n",
      "epoch  80  loss =  41.805832932028046\n",
      "epoch  81  loss =  41.78730286265408\n",
      "epoch  82  loss =  41.76915291412732\n",
      "epoch  83  loss =  41.751372480625406\n",
      "epoch  84  loss =  41.73395130852215\n",
      "epoch  85  loss =  41.71687948385255\n",
      "epoch  86  loss =  41.70014742018477\n",
      "epoch  87  loss =  41.68374584689392\n",
      "epoch  88  loss =  41.66766579783131\n",
      "epoch  89  loss =  41.65189860038164\n",
      "epoch  90  loss =  41.63643586490073\n",
      "epoch  91  loss =  41.62126947452458\n",
      "epoch  92  loss =  41.60639157534122\n",
      "epoch  93  loss =  41.591794566915496\n",
      "epoch  94  loss =  41.577471093157435\n",
      "epoch  95  loss =  41.56341403352398\n",
      "epoch  96  loss =  41.54961649454468\n",
      "epoch  97  loss =  41.5360718016604\n",
      "epoch  98  loss =  41.52277349136622\n",
      "epoch  99  loss =  41.50971530364746\n",
      "epoch  100  loss =  41.49689117469969\n",
      "epoch  101  loss =  41.48429522992289\n",
      "epoch  102  loss =  41.471921777179816\n",
      "epoch  103  loss =  41.4597653003098\n",
      "epoch  104  loss =  41.44782045288821\n",
      "epoch  105  loss =  41.43608205222316\n",
      "epoch  106  loss =  41.424545073580234\n",
      "epoch  107  loss =  41.41320464462696\n",
      "epoch  108  loss =  41.402056040088965\n",
      "epoch  109  loss =  41.39109467660929\n",
      "epoch  110  loss =  41.38031610780365\n",
      "epoch  111  loss =  41.36971601950372\n",
      "epoch  112  loss =  41.35929022518124\n",
      "epoch  113  loss =  41.34903466154619\n",
      "epoch  114  loss =  41.33894538431183\n",
      "epoch  115  loss =  41.32901856412043\n",
      "epoch  116  loss =  41.31925048262311\n",
      "epoch  117  loss =  41.30963752870788\n",
      "epoch  118  loss =  41.30017619486993\n",
      "epoch  119  loss =  41.290863073718576\n",
      "epoch  120  loss =  41.28169485461546\n",
      "epoch  121  loss =  41.27266832043879\n",
      "epoch  122  loss =  41.26378034446853\n",
      "epoch  123  loss =  41.2550278873878\n",
      "epoch  124  loss =  41.246407994395966\n",
      "epoch  125  loss =  41.237917792428675\n",
      "epoch  126  loss =  41.22955448748087\n",
      "epoch  127  loss =  41.22131536202871\n",
      "epoch  128  loss =  41.213197772546\n",
      "epoch  129  loss =  41.205199147112154\n",
      "epoch  130  loss =  41.19731698310724\n",
      "epoch  131  loss =  41.18954884499124\n",
      "epoch  132  loss =  41.18189236216403\n",
      "epoch  133  loss =  41.174345226902645\n",
      "epoch  134  loss =  41.16690519237315\n",
      "epoch  135  loss =  41.159570070714025\n",
      "epoch  136  loss =  41.15233773118812\n",
      "epoch  137  loss =  41.145206098400664\n",
      "epoch  138  loss =  41.13817315058071\n",
      "epoch  139  loss =  41.13123691792354\n",
      "epoch  140  loss =  41.12439548099144\n",
      "epoch  141  loss =  41.11764696917106\n",
      "epoch  142  loss =  41.11098955918453\n",
      "epoch  143  loss =  41.10442147365295\n",
      "epoch  144  loss =  41.097940979709435\n",
      "epoch  145  loss =  41.09154638766066\n",
      "epoch  146  loss =  41.08523604969437\n",
      "epoch  147  loss =  41.079008358631405\n",
      "epoch  148  loss =  41.07286174672046\n",
      "epoch  149  loss =  41.066794684474154\n",
      "epoch  150  loss =  41.060805679544266\n",
      "epoch  151  loss =  41.05489327563557\n",
      "epoch  152  loss =  41.04905605145588\n",
      "epoch  153  loss =  41.04329261970158\n",
      "epoch  154  loss =  41.03760162607698\n",
      "epoch  155  loss =  41.03198174834646\n",
      "epoch  156  loss =  41.026431695417905\n",
      "epoch  157  loss =  41.02095020645669\n",
      "epoch  158  loss =  41.01553605002843\n",
      "epoch  159  loss =  41.01018802327033\n",
      "epoch  160  loss =  41.00490495108914\n",
      "epoch  161  loss =  40.99968568538542\n",
      "epoch  162  loss =  40.99452910430295\n",
      "epoch  163  loss =  40.98943411150213\n",
      "epoch  164  loss =  40.98439963545701\n",
      "epoch  165  loss =  40.979424628774545\n",
      "epoch  166  loss =  40.974508067535666\n",
      "epoch  167  loss =  40.9696489506572\n",
      "epoch  168  loss =  40.96484629927404\n",
      "epoch  169  loss =  40.960099156140636\n",
      "epoch  170  loss =  40.955406585051186\n",
      "epoch  171  loss =  40.95076767027823\n",
      "epoch  172  loss =  40.94618151602824\n",
      "epoch  173  loss =  40.94164724591444\n",
      "epoch  174  loss =  40.93716400244565\n",
      "epoch  175  loss =  40.9327309465309\n",
      "epoch  176  loss =  40.928347256999146\n",
      "epoch  177  loss =  40.92401213013368\n",
      "epoch  178  loss =  40.91972477922051\n",
      "epoch  179  loss =  40.915484434110546\n",
      "epoch  180  loss =  40.91129034079482\n",
      "epoch  181  loss =  40.90714176099248\n",
      "epoch  182  loss =  40.903037971751\n",
      "epoch  183  loss =  40.898978265058396\n",
      "epoch  184  loss =  40.89496194746679\n",
      "epoch  185  loss =  40.890988339727095\n",
      "epoch  186  loss =  40.88705677643442\n",
      "epoch  187  loss =  40.883166605683826\n",
      "epoch  188  loss =  40.87931718873614\n",
      "epoch  189  loss =  40.87550789969336\n",
      "epoch  190  loss =  40.87173812518354\n",
      "epoch  191  loss =  40.86800726405458\n",
      "epoch  192  loss =  40.86431472707706\n",
      "epoch  193  loss =  40.8606599366551\n",
      "epoch  194  loss =  40.857042326545916\n",
      "epoch  195  loss =  40.85346134158695\n",
      "epoch  196  loss =  40.84991643743089\n",
      "epoch  197  loss =  40.84640708028797\n",
      "epoch  198  loss =  40.8429327466756\n",
      "epoch  199  loss =  40.83949292317496\n",
      "epoch  200  loss =  40.83608710619419\n",
      "epoch  201  loss =  40.83271480173827\n",
      "epoch  202  loss =  40.829375525185185\n",
      "epoch  203  loss =  40.82606880106822\n",
      "epoch  204  loss =  40.82279416286413\n",
      "epoch  205  loss =  40.81955115278722\n",
      "epoch  206  loss =  40.81633932158882\n",
      "epoch  207  loss =  40.813158228362255\n",
      "epoch  208  loss =  40.81000744035311\n",
      "epoch  209  loss =  40.806886532774456\n",
      "epoch  210  loss =  40.80379508862705\n",
      "epoch  211  loss =  40.80073269852428\n",
      "epoch  212  loss =  40.797698960521814\n",
      "epoch  213  loss =  40.794693479951725\n",
      "epoch  214  loss =  40.79171586926077\n",
      "epoch  215  loss =  40.78876574785321\n",
      "epoch  216  loss =  40.78584274193749\n",
      "epoch  217  loss =  40.78294648437702\n",
      "epoch  218  loss =  40.78007661454465\n",
      "epoch  219  loss =  40.77723277818114\n",
      "epoch  220  loss =  40.774414627257016\n",
      "epoch  221  loss =  40.77162181983811\n",
      "epoch  222  loss =  40.76885401995449\n",
      "epoch  223  loss =  40.766110897472515\n",
      "epoch  224  loss =  40.76339212797059\n",
      "epoch  225  loss =  40.7606973926175\n",
      "epoch  226  loss =  40.75802637805413\n",
      "epoch  227  loss =  40.755378776278086\n",
      "epoch  228  loss =  40.7527542845311\n",
      "epoch  229  loss =  40.75015260518932\n",
      "epoch  230  loss =  40.74757344565621\n",
      "epoch  231  loss =  40.74501651825822\n",
      "epoch  232  loss =  40.74248154014283\n",
      "epoch  233  loss =  40.7399682331793\n",
      "epoch  234  loss =  40.73747632386162\n",
      "epoch  235  loss =  40.735005543214\n",
      "epoch  236  loss =  40.73255562669848\n",
      "epoch  237  loss =  40.73012631412485\n",
      "epoch  238  loss =  40.72771734956281\n",
      "epoch  239  loss =  40.72532848125601\n",
      "epoch  240  loss =  40.72295946153834\n",
      "epoch  241  loss =  40.72061004675208\n",
      "epoch  242  loss =  40.718279997168096\n",
      "epoch  243  loss =  40.71596907690777\n",
      "epoch  244  loss =  40.7136770538669\n",
      "epoch  245  loss =  40.71140369964132\n",
      "epoch  246  loss =  40.7091487894542\n",
      "epoch  247  loss =  40.70691210208514\n",
      "epoch  248  loss =  40.704693419800854\n",
      "epoch  249  loss =  40.70249252828739\n",
      "epoch  250  loss =  40.700309216583996\n",
      "epoch  251  loss =  40.69814327701855\n",
      "epoch  252  loss =  40.6959945051442\n",
      "epoch  253  loss =  40.69386269967781\n",
      "epoch  254  loss =  40.69174766243949\n",
      "epoch  255  loss =  40.68964919829367\n",
      "epoch  256  loss =  40.68756711509145\n",
      "epoch  257  loss =  40.68550122361419\n",
      "epoch  258  loss =  40.683451337518456\n",
      "epoch  259  loss =  40.68141727328212\n",
      "epoch  260  loss =  40.67939885015169\n",
      "epoch  261  loss =  40.67739589009077\n",
      "epoch  262  loss =  40.67540821772968\n",
      "epoch  263  loss =  40.6734356603162\n",
      "epoch  264  loss =  40.67147804766735\n",
      "epoch  265  loss =  40.669535212122284\n",
      "epoch  266  loss =  40.66760698849608\n",
      "epoch  267  loss =  40.66569321403473\n",
      "epoch  268  loss =  40.663793728370855\n",
      "epoch  269  loss =  40.66190837348069\n",
      "epoch  270  loss =  40.660036993641604\n",
      "epoch  271  loss =  40.6581794353909\n",
      "epoch  272  loss =  40.656335547485206\n",
      "epoch  273  loss =  40.65450518086092\n",
      "epoch  274  loss =  40.652688188595384\n",
      "epoch  275  loss =  40.650884425868945\n",
      "epoch  276  loss =  40.64909374992776\n",
      "epoch  277  loss =  40.64731602004736\n",
      "epoch  278  loss =  40.64555109749711\n",
      "epoch  279  loss =  40.64379884550526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  280  loss =  40.64205912922472\n",
      "epoch  281  loss =  40.64033181569975\n",
      "epoch  282  loss =  40.63861677383302\n",
      "epoch  283  loss =  40.63691387435363\n",
      "epoch  284  loss =  40.6352229897856\n",
      "epoch  285  loss =  40.63354399441716\n",
      "epoch  286  loss =  40.63187676427043\n",
      "epoch  287  loss =  40.630221177072\n",
      "epoch  288  loss =  40.628577112223915\n",
      "epoch  289  loss =  40.626944450775284\n",
      "epoch  290  loss =  40.625323075394476\n",
      "epoch  291  loss =  40.62371287034192\n",
      "epoch  292  loss =  40.62211372144329\n",
      "epoch  293  loss =  40.62052551606349\n",
      "epoch  294  loss =  40.6189481430808\n",
      "epoch  295  loss =  40.61738149286193\n",
      "epoch  296  loss =  40.61582545723721\n",
      "epoch  297  loss =  40.61427992947653\n",
      "epoch  298  loss =  40.61274480426556\n",
      "epoch  299  loss =  40.611219977682616\n",
      "epoch  300  loss =  40.609705347175776\n",
      "epoch  301  loss =  40.60820081154062\n",
      "epoch  302  loss =  40.60670627089835\n",
      "epoch  303  loss =  40.60522162667418\n",
      "epoch  304  loss =  40.60374678157645\n",
      "epoch  305  loss =  40.60228163957578\n",
      "epoch  306  loss =  40.600826105884934\n",
      "epoch  307  loss =  40.59938008693892\n",
      "epoch  308  loss =  40.597943490375414\n",
      "epoch  309  loss =  40.596516225015726\n",
      "epoch  310  loss =  40.59509820084594\n",
      "epoch  311  loss =  40.593689328998565\n",
      "epoch  312  loss =  40.59228952173441\n",
      "epoch  313  loss =  40.59089869242491\n",
      "epoch  314  loss =  40.589516755534646\n",
      "epoch  315  loss =  40.588143626604335\n",
      "epoch  316  loss =  40.586779222234064\n",
      "epoch  317  loss =  40.58542346006679\n",
      "epoch  318  loss =  40.584076258772214\n",
      "epoch  319  loss =  40.58273753803098\n",
      "epoch  320  loss =  40.58140721851906\n",
      "epoch  321  loss =  40.58008522189245\n",
      "epoch  322  loss =  40.578771470772324\n",
      "epoch  323  loss =  40.57746588873008\n",
      "epoch  324  loss =  40.57616840027311\n",
      "epoch  325  loss =  40.574878930830465\n",
      "epoch  326  loss =  40.57359740673899\n",
      "epoch  327  loss =  40.57232375522954\n",
      "epoch  328  loss =  40.57105790441366\n",
      "epoch  329  loss =  40.5697997832703\n",
      "epoch  330  loss =  40.568549321632894\n",
      "epoch  331  loss =  40.56730645017659\n",
      "epoch  332  loss =  40.56607110040574\n",
      "epoch  333  loss =  40.56484320464164\n",
      "epoch  334  loss =  40.56362269601045\n",
      "epoch  335  loss =  40.5624095084313\n",
      "epoch  336  loss =  40.56120357660468\n",
      "epoch  337  loss =  40.56000483600096\n",
      "epoch  338  loss =  40.55881322284916\n",
      "epoch  339  loss =  40.55762867412591\n",
      "epoch  340  loss =  40.556451127544534\n",
      "epoch  341  loss =  40.55528052154443\n",
      "epoch  342  loss =  40.55411679528057\n",
      "epoch  343  loss =  40.55295988861314\n",
      "epoch  344  loss =  40.55180974209749\n",
      "epoch  345  loss =  40.5506662969741\n",
      "epoch  346  loss =  40.549529495158865\n",
      "epoch  347  loss =  40.54839927923337\n",
      "epoch  348  loss =  40.54727559243552\n",
      "epoch  349  loss =  40.54615837865021\n",
      "epoch  350  loss =  40.54504758240014\n",
      "epoch  351  loss =  40.54394314883692\n",
      "epoch  352  loss =  40.54284502373215\n",
      "epoch  353  loss =  40.541753153468726\n",
      "epoch  354  loss =  40.54066748503237\n",
      "epoch  355  loss =  40.539587966003126\n",
      "epoch  356  loss =  40.538514544547205\n",
      "epoch  357  loss =  40.53744716940874\n",
      "epoch  358  loss =  40.53638578990191\n",
      "epoch  359  loss =  40.535330355903\n",
      "epoch  360  loss =  40.534280817842635\n",
      "epoch  361  loss =  40.53323712669831\n",
      "epoch  362  loss =  40.5321992339868\n",
      "epoch  363  loss =  40.53116709175681\n",
      "epoch  364  loss =  40.53014065258177\n",
      "epoch  365  loss =  40.529119869552694\n",
      "epoch  366  loss =  40.52810469627116\n",
      "epoch  367  loss =  40.52709508684242\n",
      "epoch  368  loss =  40.526090995868664\n",
      "epoch  369  loss =  40.52509237844229\n",
      "epoch  370  loss =  40.52409919013933\n",
      "epoch  371  loss =  40.523111387013\n",
      "epoch  372  loss =  40.522128925587396\n",
      "epoch  373  loss =  40.521151762851176\n",
      "epoch  374  loss =  40.52017985625135\n",
      "epoch  375  loss =  40.519213163687354\n",
      "epoch  376  loss =  40.51825164350497\n",
      "epoch  377  loss =  40.51729525449048\n",
      "epoch  378  loss =  40.5163439558649\n",
      "epoch  379  loss =  40.5153977072783\n",
      "epoch  380  loss =  40.51445646880415\n",
      "epoch  381  loss =  40.51352020093389\n",
      "epoch  382  loss =  40.512588864571384\n",
      "epoch  383  loss =  40.51166242102767\n",
      "epoch  384  loss =  40.51074083201567\n",
      "epoch  385  loss =  40.509824059645\n",
      "epoch  386  loss =  40.508912066416855\n",
      "epoch  387  loss =  40.50800481521904\n",
      "epoch  388  loss =  40.507102269320924\n",
      "epoch  389  loss =  40.50620439236869\n",
      "epoch  390  loss =  40.50531114838044\n",
      "epoch  391  loss =  40.50442250174152\n",
      "epoch  392  loss =  40.50353841719983\n",
      "epoch  393  loss =  40.50265885986127\n",
      "epoch  394  loss =  40.501783795185254\n",
      "epoch  395  loss =  40.50091318898019\n",
      "epoch  396  loss =  40.50004700739915\n",
      "epoch  397  loss =  40.499185216935544\n",
      "epoch  398  loss =  40.49832778441886\n",
      "epoch  399  loss =  40.49747467701054\n",
      "epoch  400  loss =  40.496625862199735\n",
      "epoch  401  loss =  40.49578130779935\n",
      "epoch  402  loss =  40.494940981942\n",
      "epoch  403  loss =  40.49410485307608\n",
      "epoch  404  loss =  40.493272889961844\n",
      "epoch  405  loss =  40.49244506166761\n",
      "epoch  406  loss =  40.49162133756597\n",
      "epoch  407  loss =  40.49080168733009\n",
      "epoch  408  loss =  40.48998608093004\n",
      "epoch  409  loss =  40.48917448862916\n",
      "epoch  410  loss =  40.48836688098053\n",
      "epoch  411  loss =  40.48756322882347\n",
      "epoch  412  loss =  40.48676350328003\n",
      "epoch  413  loss =  40.48596767575167\n",
      "epoch  414  loss =  40.485175717915794\n",
      "epoch  415  loss =  40.48438760172256\n",
      "epoch  416  loss =  40.48360329939156\n",
      "epoch  417  loss =  40.48282278340853\n",
      "epoch  418  loss =  40.48204602652235\n",
      "epoch  419  loss =  40.48127300174174\n",
      "epoch  420  loss =  40.480503682332326\n",
      "epoch  421  loss =  40.47973804181353\n",
      "epoch  422  loss =  40.47897605395555\n",
      "epoch  423  loss =  40.47821769277648\n",
      "epoch  424  loss =  40.47746293253935\n",
      "epoch  425  loss =  40.476711747749306\n",
      "epoch  426  loss =  40.47596411315068\n",
      "epoch  427  loss =  40.47522000372432\n",
      "epoch  428  loss =  40.47447939468477\n",
      "epoch  429  loss =  40.47374226147756\n",
      "epoch  430  loss =  40.47300857977655\n",
      "epoch  431  loss =  40.47227832548132\n",
      "epoch  432  loss =  40.47155147471444\n",
      "epoch  433  loss =  40.4708280038191\n",
      "epoch  434  loss =  40.470107889356406\n",
      "epoch  435  loss =  40.469391108102954\n",
      "epoch  436  loss =  40.46867763704843\n",
      "epoch  437  loss =  40.46796745339304\n",
      "epoch  438  loss =  40.467260534545225\n",
      "epoch  439  loss =  40.46655685811925\n",
      "epoch  440  loss =  40.465856401932925\n",
      "epoch  441  loss =  40.465159144005206\n",
      "epoch  442  loss =  40.46446506255404\n",
      "epoch  443  loss =  40.46377413599406\n",
      "epoch  444  loss =  40.463086342934375\n",
      "epoch  445  loss =  40.46240166217642\n",
      "epoch  446  loss =  40.4617200727118\n",
      "epoch  447  loss =  40.46104155372014\n",
      "epoch  448  loss =  40.46036608456704\n",
      "epoch  449  loss =  40.45969364480199\n",
      "epoch  450  loss =  40.4590242141563\n",
      "epoch  451  loss =  40.458357772541156\n",
      "epoch  452  loss =  40.45769430004555\n",
      "epoch  453  loss =  40.457033776934445\n",
      "epoch  454  loss =  40.45637618364668\n",
      "epoch  455  loss =  40.45572150079321\n",
      "epoch  456  loss =  40.45506970915515\n",
      "epoch  457  loss =  40.45442078968195\n",
      "epoch  458  loss =  40.45377472348953\n",
      "epoch  459  loss =  40.453131491858485\n",
      "epoch  460  loss =  40.4524910762323\n",
      "epoch  461  loss =  40.45185345821561\n",
      "epoch  462  loss =  40.45121861957243\n",
      "epoch  463  loss =  40.45058654222442\n",
      "epoch  464  loss =  40.449957208249266\n",
      "epoch  465  loss =  40.449330599878905\n",
      "epoch  466  loss =  40.44870669949796\n",
      "epoch  467  loss =  40.44808548964207\n",
      "epoch  468  loss =  40.447466952996265\n",
      "epoch  469  loss =  40.4468510723934\n",
      "epoch  470  loss =  40.44623783081261\n",
      "epoch  471  loss =  40.4456272113777\n",
      "epoch  472  loss =  40.44501919735565\n",
      "epoch  473  loss =  40.4444137721551\n",
      "epoch  474  loss =  40.44381091932487\n",
      "epoch  475  loss =  40.44321062255248\n",
      "epoch  476  loss =  40.44261286566266\n",
      "epoch  477  loss =  40.442017632615965\n",
      "epoch  478  loss =  40.441424907507354\n",
      "epoch  479  loss =  40.44083467456474\n",
      "epoch  480  loss =  40.440246918147665\n",
      "epoch  481  loss =  40.439661622745895\n",
      "epoch  482  loss =  40.43907877297811\n",
      "epoch  483  loss =  40.438498353590475\n",
      "epoch  484  loss =  40.43792034945548\n",
      "epoch  485  loss =  40.43734474557051\n",
      "epoch  486  loss =  40.43677152705662\n",
      "epoch  487  loss =  40.43620067915725\n",
      "epoch  488  loss =  40.43563218723697\n",
      "epoch  489  loss =  40.435066036780256\n",
      "epoch  490  loss =  40.43450221339026\n",
      "epoch  491  loss =  40.43394070278761\n",
      "epoch  492  loss =  40.433381490809204\n",
      "epoch  493  loss =  40.43282456340704\n",
      "epoch  494  loss =  40.432269906647036\n",
      "epoch  495  loss =  40.43171750670796\n",
      "epoch  496  loss =  40.43116734988014\n",
      "epoch  497  loss =  40.43061942256449\n",
      "epoch  498  loss =  40.430073711271355\n",
      "epoch  499  loss =  40.42953020261932\n",
      "epoch  500  loss =  40.42898888333434\n",
      "epoch  501  loss =  40.42844974024841\n",
      "epoch  502  loss =  40.427912760298746\n",
      "epoch  503  loss =  40.42737793052659\n",
      "epoch  504  loss =  40.42684523807618\n",
      "epoch  505  loss =  40.42631467019387\n",
      "epoch  506  loss =  40.42578621422697\n",
      "epoch  507  loss =  40.42525985762278\n",
      "epoch  508  loss =  40.4247355879277\n",
      "epoch  509  loss =  40.42421339278616\n",
      "epoch  510  loss =  40.42369325993966\n",
      "epoch  511  loss =  40.42317517722591\n",
      "epoch  512  loss =  40.42265913257777\n",
      "epoch  513  loss =  40.42214511402245\n",
      "epoch  514  loss =  40.42163310968048\n",
      "epoch  515  loss =  40.42112310776484\n",
      "epoch  516  loss =  40.42061509658012\n",
      "epoch  517  loss =  40.420109064521576\n",
      "epoch  518  loss =  40.41960500007425\n",
      "epoch  519  loss =  40.419102891812145\n",
      "epoch  520  loss =  40.41860272839736\n",
      "epoch  521  loss =  40.418104498579176\n",
      "epoch  522  loss =  40.417608191193345\n",
      "epoch  523  loss =  40.41711379516118\n",
      "epoch  524  loss =  40.416621299488746\n",
      "epoch  525  loss =  40.41613069326604\n",
      "epoch  526  loss =  40.41564196566629\n",
      "epoch  527  loss =  40.415155105945004\n",
      "epoch  528  loss =  40.41467010343933\n",
      "epoch  529  loss =  40.41418694756723\n",
      "epoch  530  loss =  40.413705627826715\n",
      "epoch  531  loss =  40.41322613379507\n",
      "epoch  532  loss =  40.4127484551282\n",
      "epoch  533  loss =  40.41227258155975\n",
      "epoch  534  loss =  40.41179850290051\n",
      "epoch  535  loss =  40.41132620903762\n",
      "epoch  536  loss =  40.41085568993388\n",
      "epoch  537  loss =  40.41038693562704\n",
      "epoch  538  loss =  40.40991993622909\n",
      "epoch  539  loss =  40.40945468192563\n",
      "epoch  540  loss =  40.40899116297509\n",
      "epoch  541  loss =  40.408529369708155\n",
      "epoch  542  loss =  40.408069292527024\n",
      "epoch  543  loss =  40.40761092190479\n",
      "epoch  544  loss =  40.40715424838481\n",
      "epoch  545  loss =  40.406699262579984\n",
      "epoch  546  loss =  40.40624595517218\n",
      "epoch  547  loss =  40.4057943169116\n",
      "epoch  548  loss =  40.40534433861612\n",
      "epoch  549  loss =  40.404896011170734\n",
      "epoch  550  loss =  40.404449325526855\n",
      "epoch  551  loss =  40.40400427270182\n",
      "epoch  552  loss =  40.40356084377816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  553  loss =  40.40311902990318\n",
      "epoch  554  loss =  40.402678822288216\n",
      "epoch  555  loss =  40.402240212208135\n",
      "epoch  556  loss =  40.40180319100073\n",
      "epoch  557  loss =  40.40136775006623\n",
      "epoch  558  loss =  40.40093388086664\n",
      "epoch  559  loss =  40.40050157492523\n",
      "epoch  560  loss =  40.40007082382601\n",
      "epoch  561  loss =  40.399641619213185\n",
      "epoch  562  loss =  40.39921395279055\n",
      "epoch  563  loss =  40.398787816321054\n",
      "epoch  564  loss =  40.398363201626225\n",
      "epoch  565  loss =  40.39794010058566\n",
      "epoch  566  loss =  40.3975185051365\n",
      "epoch  567  loss =  40.39709840727296\n",
      "epoch  568  loss =  40.39667979904578\n",
      "epoch  569  loss =  40.39626267256174\n",
      "epoch  570  loss =  40.39584701998321\n",
      "epoch  571  loss =  40.395432833527565\n",
      "epoch  572  loss =  40.395020105466855\n",
      "epoch  573  loss =  40.394608828127176\n",
      "epoch  574  loss =  40.39419899388828\n",
      "epoch  575  loss =  40.393790595183084\n",
      "epoch  576  loss =  40.393383624497226\n",
      "epoch  577  loss =  40.3929780743686\n",
      "epoch  578  loss =  40.39257393738687\n",
      "epoch  579  loss =  40.392171206193076\n",
      "epoch  580  loss =  40.39176987347918\n",
      "epoch  581  loss =  40.391369931987576\n",
      "epoch  582  loss =  40.390971374510734\n",
      "epoch  583  loss =  40.3905741938907\n",
      "epoch  584  loss =  40.39017838301871\n",
      "epoch  585  loss =  40.38978393483476\n",
      "epoch  586  loss =  40.38939084232718\n",
      "epoch  587  loss =  40.38899909853228\n",
      "epoch  588  loss =  40.38860869653383\n",
      "epoch  589  loss =  40.38821962946274\n",
      "epoch  590  loss =  40.387831890496635\n",
      "epoch  591  loss =  40.38744547285951\n",
      "epoch  592  loss =  40.38706036982122\n",
      "epoch  593  loss =  40.38667657469722\n",
      "epoch  594  loss =  40.38629408084808\n",
      "epoch  595  loss =  40.3859128816792\n",
      "epoch  596  loss =  40.38553297064033\n",
      "epoch  597  loss =  40.3851543412253\n",
      "epoch  598  loss =  40.38477698697155\n",
      "epoch  599  loss =  40.3844009014599\n",
      "epoch  600  loss =  40.38402607831401\n",
      "epoch  601  loss =  40.38365251120018\n",
      "epoch  602  loss =  40.38328019382693\n",
      "epoch  603  loss =  40.38290911994463\n",
      "epoch  604  loss =  40.382539283345174\n",
      "epoch  605  loss =  40.38217067786168\n",
      "epoch  606  loss =  40.38180329736807\n",
      "epoch  607  loss =  40.381437135778775\n",
      "epoch  608  loss =  40.381072187048446\n",
      "epoch  609  loss =  40.380708445171486\n",
      "epoch  610  loss =  40.38034590418188\n",
      "epoch  611  loss =  40.379984558152785\n",
      "epoch  612  loss =  40.379624401196246\n",
      "epoch  613  loss =  40.37926542746282\n",
      "epoch  614  loss =  40.378907631141345\n",
      "epoch  615  loss =  40.378551006458544\n",
      "epoch  616  loss =  40.37819554767881\n",
      "epoch  617  loss =  40.37784124910378\n",
      "epoch  618  loss =  40.37748810507218\n",
      "epoch  619  loss =  40.37713610995939\n",
      "epoch  620  loss =  40.3767852581772\n",
      "epoch  621  loss =  40.37643554417356\n",
      "epoch  622  loss =  40.37608696243224\n",
      "epoch  623  loss =  40.375739507472524\n",
      "epoch  624  loss =  40.375393173849\n",
      "epoch  625  loss =  40.37504795615115\n",
      "epoch  626  loss =  40.37470384900324\n",
      "epoch  627  loss =  40.374360847063905\n",
      "epoch  628  loss =  40.374018945025924\n",
      "epoch  629  loss =  40.37367813761595\n",
      "epoch  630  loss =  40.37333841959425\n",
      "epoch  631  loss =  40.37299978575441\n",
      "epoch  632  loss =  40.37266223092307\n",
      "epoch  633  loss =  40.372325749959735\n",
      "epoch  634  loss =  40.37199033775637\n",
      "epoch  635  loss =  40.37165598923733\n",
      "epoch  636  loss =  40.37132269935895\n",
      "epoch  637  loss =  40.37099046310935\n",
      "epoch  638  loss =  40.37065927550822\n",
      "epoch  639  loss =  40.370329131606475\n",
      "epoch  640  loss =  40.37000002648616\n",
      "epoch  641  loss =  40.36967195526005\n",
      "epoch  642  loss =  40.36934491307154\n",
      "epoch  643  loss =  40.369018895094285\n",
      "epoch  644  loss =  40.368693896532044\n",
      "epoch  645  loss =  40.36836991261849\n",
      "epoch  646  loss =  40.36804693861685\n",
      "epoch  647  loss =  40.36772496981976\n",
      "epoch  648  loss =  40.36740400154901\n",
      "epoch  649  loss =  40.36708402915537\n",
      "epoch  650  loss =  40.366765048018294\n",
      "epoch  651  loss =  40.366447053545734\n",
      "epoch  652  loss =  40.366130041173925\n",
      "epoch  653  loss =  40.36581400636717\n",
      "epoch  654  loss =  40.36549894461758\n",
      "epoch  655  loss =  40.365184851444944\n",
      "epoch  656  loss =  40.36487172239646\n",
      "epoch  657  loss =  40.3645595530465\n",
      "epoch  658  loss =  40.36424833899649\n",
      "epoch  659  loss =  40.36393807587464\n",
      "epoch  660  loss =  40.36362875933574\n",
      "epoch  661  loss =  40.363320385060995\n",
      "epoch  662  loss =  40.363012948757756\n",
      "epoch  663  loss =  40.36270644615945\n",
      "epoch  664  loss =  40.362400873025244\n",
      "epoch  665  loss =  40.36209622513991\n",
      "epoch  666  loss =  40.361792498313676\n",
      "epoch  667  loss =  40.36148968838194\n",
      "epoch  668  loss =  40.36118779120518\n",
      "epoch  669  loss =  40.36088680266866\n",
      "epoch  670  loss =  40.360586718682406\n",
      "epoch  671  loss =  40.360287535180774\n",
      "epoch  672  loss =  40.35998924812254\n",
      "epoch  673  loss =  40.35969185349052\n",
      "epoch  674  loss =  40.359395347291496\n",
      "epoch  675  loss =  40.359099725555986\n",
      "epoch  676  loss =  40.3588049843381\n",
      "epoch  677  loss =  40.35851111971533\n",
      "epoch  678  loss =  40.35821812778842\n",
      "epoch  679  loss =  40.357926004681175\n",
      "epoch  680  loss =  40.35763474654027\n",
      "epoch  681  loss =  40.35734434953512\n",
      "epoch  682  loss =  40.35705480985767\n",
      "epoch  683  loss =  40.35676612372228\n",
      "epoch  684  loss =  40.35647828736554\n",
      "epoch  685  loss =  40.35619129704605\n",
      "epoch  686  loss =  40.35590514904438\n",
      "epoch  687  loss =  40.35561983966278\n",
      "epoch  688  loss =  40.35533536522512\n",
      "epoch  689  loss =  40.355051722076674\n",
      "epoch  690  loss =  40.35476890658402\n",
      "epoch  691  loss =  40.354486915134785\n",
      "epoch  692  loss =  40.35420574413763\n",
      "epoch  693  loss =  40.353925390022006\n",
      "epoch  694  loss =  40.35364584923798\n",
      "epoch  695  loss =  40.353367118256195\n",
      "epoch  696  loss =  40.35308919356762\n",
      "epoch  697  loss =  40.35281207168343\n",
      "epoch  698  loss =  40.35253574913492\n",
      "epoch  699  loss =  40.35226022247326\n",
      "epoch  700  loss =  40.35198548826946\n",
      "epoch  701  loss =  40.35171154311412\n",
      "epoch  702  loss =  40.35143838361738\n",
      "epoch  703  loss =  40.35116600640871\n",
      "epoch  704  loss =  40.35089440813684\n",
      "epoch  705  loss =  40.35062358546958\n",
      "epoch  706  loss =  40.350353535093696\n",
      "epoch  707  loss =  40.350084253714776\n",
      "epoch  708  loss =  40.34981573805706\n",
      "epoch  709  loss =  40.3495479848634\n",
      "epoch  710  loss =  40.34928099089504\n",
      "epoch  711  loss =  40.3490147529315\n",
      "epoch  712  loss =  40.348749267770515\n",
      "epoch  713  loss =  40.3484845322278\n",
      "epoch  714  loss =  40.34822054313702\n",
      "epoch  715  loss =  40.347957297349616\n",
      "epoch  716  loss =  40.347694791734675\n",
      "epoch  717  loss =  40.34743302317885\n",
      "epoch  718  loss =  40.34717198858616\n",
      "epoch  719  loss =  40.34691168487797\n",
      "epoch  720  loss =  40.3466521089928\n",
      "epoch  721  loss =  40.346393257886206\n",
      "epoch  722  loss =  40.34613512853068\n",
      "epoch  723  loss =  40.345877717915556\n",
      "epoch  724  loss =  40.34562102304684\n",
      "epoch  725  loss =  40.34536504094716\n",
      "epoch  726  loss =  40.345109768655576\n",
      "epoch  727  loss =  40.34485520322751\n",
      "epoch  728  loss =  40.34460134173465\n",
      "epoch  729  loss =  40.34434818126481\n",
      "epoch  730  loss =  40.34409571892184\n",
      "epoch  731  loss =  40.343843951825455\n",
      "epoch  732  loss =  40.343592877111206\n",
      "epoch  733  loss =  40.343342491930336\n",
      "epoch  734  loss =  40.34309279344969\n",
      "epoch  735  loss =  40.342843778851545\n",
      "epoch  736  loss =  40.34259544533363\n",
      "epoch  737  loss =  40.34234779010887\n",
      "epoch  738  loss =  40.34210081040541\n",
      "epoch  739  loss =  40.34185450346644\n",
      "epoch  740  loss =  40.341608866550104\n",
      "epoch  741  loss =  40.3413638969294\n",
      "epoch  742  loss =  40.34111959189214\n",
      "epoch  743  loss =  40.34087594874072\n",
      "epoch  744  loss =  40.34063296479218\n",
      "epoch  745  loss =  40.340390637377936\n",
      "epoch  746  loss =  40.34014896384386\n",
      "epoch  747  loss =  40.33990794155004\n",
      "epoch  748  loss =  40.339667567870734\n",
      "epoch  749  loss =  40.339427840194304\n",
      "epoch  750  loss =  40.339188755923104\n",
      "epoch  751  loss =  40.33895031247336\n",
      "epoch  752  loss =  40.3387125072751\n",
      "epoch  753  loss =  40.338475337772074\n",
      "epoch  754  loss =  40.33823880142164\n",
      "epoch  755  loss =  40.33800289569468\n",
      "epoch  756  loss =  40.337767618075524\n",
      "epoch  757  loss =  40.33753296606184\n",
      "epoch  758  loss =  40.33729893716455\n",
      "epoch  759  loss =  40.33706552890775\n",
      "epoch  760  loss =  40.33683273882864\n",
      "epoch  761  loss =  40.33660056447739\n",
      "epoch  762  loss =  40.33636900341712\n",
      "epoch  763  loss =  40.33613805322371\n",
      "epoch  764  loss =  40.3359077114859\n",
      "epoch  765  loss =  40.33567797580495\n",
      "epoch  766  loss =  40.33544884379481\n",
      "epoch  767  loss =  40.33522031308186\n",
      "epoch  768  loss =  40.33499238130494\n",
      "epoch  769  loss =  40.33476504611517\n",
      "epoch  770  loss =  40.334538305175975\n",
      "epoch  771  loss =  40.33431215616292\n",
      "epoch  772  loss =  40.33408659676367\n",
      "epoch  773  loss =  40.33386162467792\n",
      "epoch  774  loss =  40.33363723761728\n",
      "epoch  775  loss =  40.33341343330524\n",
      "epoch  776  loss =  40.33319020947705\n",
      "epoch  777  loss =  40.33296756387968\n",
      "epoch  778  loss =  40.33274549427175\n",
      "epoch  779  loss =  40.33252399842341\n",
      "epoch  780  loss =  40.33230307411631\n",
      "epoch  781  loss =  40.33208271914351\n",
      "epoch  782  loss =  40.33186293130936\n",
      "epoch  783  loss =  40.33164370842955\n",
      "epoch  784  loss =  40.331425048330914\n",
      "epoch  785  loss =  40.331206948851396\n",
      "epoch  786  loss =  40.33098940784003\n",
      "epoch  787  loss =  40.33077242315678\n",
      "epoch  788  loss =  40.33055599267255\n",
      "epoch  789  loss =  40.33034011426911\n",
      "epoch  790  loss =  40.330124785838926\n",
      "epoch  791  loss =  40.329910005285214\n",
      "epoch  792  loss =  40.32969577052183\n",
      "epoch  793  loss =  40.329482079473166\n",
      "epoch  794  loss =  40.32926893007414\n",
      "epoch  795  loss =  40.329056320270084\n",
      "epoch  796  loss =  40.328844248016736\n",
      "epoch  797  loss =  40.32863271128009\n",
      "epoch  798  loss =  40.328421708036394\n",
      "epoch  799  loss =  40.3282112362721\n",
      "epoch  800  loss =  40.32800129398372\n",
      "epoch  801  loss =  40.327791879177845\n",
      "epoch  802  loss =  40.32758298987104\n",
      "epoch  803  loss =  40.32737462408979\n",
      "epoch  804  loss =  40.32716677987045\n",
      "epoch  805  loss =  40.32695945525917\n",
      "epoch  806  loss =  40.32675264831183\n",
      "epoch  807  loss =  40.32654635709398\n",
      "epoch  808  loss =  40.32634057968081\n",
      "epoch  809  loss =  40.32613531415706\n",
      "epoch  810  loss =  40.32593055861695\n",
      "epoch  811  loss =  40.32572631116415\n",
      "epoch  812  loss =  40.32552256991171\n",
      "epoch  813  loss =  40.32531933298202\n",
      "epoch  814  loss =  40.32511659850671\n",
      "epoch  815  loss =  40.32491436462663\n",
      "epoch  816  loss =  40.32471262949179\n",
      "epoch  817  loss =  40.32451139126127\n",
      "epoch  818  loss =  40.32431064810321\n",
      "epoch  819  loss =  40.32411039819475\n",
      "epoch  820  loss =  40.3239106397219\n",
      "epoch  821  loss =  40.32371137087962\n",
      "epoch  822  loss =  40.32351258987166\n",
      "epoch  823  loss =  40.3233142949105\n",
      "epoch  824  loss =  40.323116484217415\n",
      "epoch  825  loss =  40.32291915602224\n",
      "epoch  826  loss =  40.32272230856351\n",
      "epoch  827  loss =  40.322525940088255\n",
      "epoch  828  loss =  40.32233004885203\n",
      "epoch  829  loss =  40.322134633118864\n",
      "epoch  830  loss =  40.321939691161155\n",
      "epoch  831  loss =  40.32174522125966\n",
      "epoch  832  loss =  40.32155122170344\n",
      "epoch  833  loss =  40.32135769078981\n",
      "epoch  834  loss =  40.321164626824284\n",
      "epoch  835  loss =  40.320972028120536\n",
      "epoch  836  loss =  40.32077989300031\n",
      "epoch  837  loss =  40.320588219793436\n",
      "epoch  838  loss =  40.320397006837744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  839  loss =  40.320206252479025\n",
      "epoch  840  loss =  40.32001595507097\n",
      "epoch  841  loss =  40.319826112975115\n",
      "epoch  842  loss =  40.31963672456089\n",
      "epoch  843  loss =  40.31944778820538\n",
      "epoch  844  loss =  40.31925930229348\n",
      "epoch  845  loss =  40.31907126521774\n",
      "epoch  846  loss =  40.31888367537835\n",
      "epoch  847  loss =  40.31869653118305\n",
      "epoch  848  loss =  40.318509831047166\n",
      "epoch  849  loss =  40.318323573393485\n",
      "epoch  850  loss =  40.318137756652305\n",
      "epoch  851  loss =  40.31795237926124\n",
      "epoch  852  loss =  40.31776743966539\n",
      "epoch  853  loss =  40.31758293631707\n",
      "epoch  854  loss =  40.317398867675934\n",
      "epoch  855  loss =  40.31721523220883\n",
      "epoch  856  loss =  40.31703202838986\n",
      "epoch  857  loss =  40.31684925470022\n",
      "epoch  858  loss =  40.31666690962828\n",
      "epoch  859  loss =  40.3164849916694\n",
      "epoch  860  loss =  40.31630349932604\n",
      "epoch  861  loss =  40.31612243110757\n",
      "epoch  862  loss =  40.31594178553041\n",
      "epoch  863  loss =  40.315761561117775\n",
      "epoch  864  loss =  40.31558175639984\n",
      "epoch  865  loss =  40.31540236991353\n",
      "epoch  866  loss =  40.31522340020262\n",
      "epoch  867  loss =  40.31504484581758\n",
      "epoch  868  loss =  40.31486670531561\n",
      "epoch  869  loss =  40.3146889772606\n",
      "epoch  870  loss =  40.31451166022303\n",
      "epoch  871  loss =  40.314334752780006\n",
      "epoch  872  loss =  40.31415825351518\n",
      "epoch  873  loss =  40.3139821610187\n",
      "epoch  874  loss =  40.31380647388721\n",
      "epoch  875  loss =  40.313631190723825\n",
      "epoch  876  loss =  40.313456310138015\n",
      "epoch  877  loss =  40.31328183074564\n",
      "epoch  878  loss =  40.3131077511689\n",
      "epoch  879  loss =  40.31293407003629\n",
      "epoch  880  loss =  40.31276078598255\n",
      "epoch  881  loss =  40.31258789764867\n",
      "epoch  882  loss =  40.312415403681804\n",
      "epoch  883  loss =  40.3122433027353\n",
      "epoch  884  loss =  40.31207159346854\n",
      "epoch  885  loss =  40.31190027454711\n",
      "epoch  886  loss =  40.311729344642536\n",
      "epoch  887  loss =  40.31155880243245\n",
      "epoch  888  loss =  40.31138864660039\n",
      "epoch  889  loss =  40.311218875835905\n",
      "epoch  890  loss =  40.31104948883441\n",
      "epoch  891  loss =  40.310880484297236\n",
      "epoch  892  loss =  40.310711860931534\n",
      "epoch  893  loss =  40.31054361745029\n",
      "epoch  894  loss =  40.31037575257228\n",
      "epoch  895  loss =  40.31020826502198\n",
      "epoch  896  loss =  40.31004115352967\n",
      "epoch  897  loss =  40.30987441683126\n",
      "epoch  898  loss =  40.309708053668295\n",
      "epoch  899  loss =  40.309542062788\n",
      "epoch  900  loss =  40.30937644294313\n",
      "epoch  901  loss =  40.30921119289207\n",
      "epoch  902  loss =  40.30904631139867\n",
      "epoch  903  loss =  40.30888179723234\n",
      "epoch  904  loss =  40.308717649167875\n",
      "epoch  905  loss =  40.308553865985594\n",
      "epoch  906  loss =  40.30839044647119\n",
      "epoch  907  loss =  40.308227389415705\n",
      "epoch  908  loss =  40.308064693615584\n",
      "epoch  909  loss =  40.30790235787254\n",
      "epoch  910  loss =  40.30774038099362\n",
      "epoch  911  loss =  40.307578761791106\n",
      "epoch  912  loss =  40.307417499082476\n",
      "epoch  913  loss =  40.30725659169049\n",
      "epoch  914  loss =  40.307096038443035\n",
      "epoch  915  loss =  40.306935838173146\n",
      "epoch  916  loss =  40.30677598971898\n",
      "epoch  917  loss =  40.306616491923755\n",
      "epoch  918  loss =  40.30645734363583\n",
      "epoch  919  loss =  40.30629854370852\n",
      "epoch  920  loss =  40.30614009100016\n",
      "epoch  921  loss =  40.30598198437409\n",
      "epoch  922  loss =  40.3058242226986\n",
      "epoch  923  loss =  40.30566680484687\n",
      "epoch  924  loss =  40.30550972969703\n",
      "epoch  925  loss =  40.305352996132044\n",
      "epoch  926  loss =  40.30519660303972\n",
      "epoch  927  loss =  40.3050405493127\n",
      "epoch  928  loss =  40.30488483384845\n",
      "epoch  929  loss =  40.304729455549136\n",
      "epoch  930  loss =  40.3045744133217\n",
      "epoch  931  loss =  40.30441970607782\n",
      "epoch  932  loss =  40.30426533273382\n",
      "epoch  933  loss =  40.30411129221077\n",
      "epoch  934  loss =  40.30395758343426\n",
      "epoch  935  loss =  40.3038042053346\n",
      "epoch  936  loss =  40.30365115684661\n",
      "epoch  937  loss =  40.30349843690977\n",
      "epoch  938  loss =  40.30334604446803\n",
      "epoch  939  loss =  40.303193978469864\n",
      "epoch  940  loss =  40.303042237868254\n",
      "epoch  941  loss =  40.302890821620664\n",
      "epoch  942  loss =  40.302739728688984\n",
      "epoch  943  loss =  40.30258895803953\n",
      "epoch  944  loss =  40.302438508643\n",
      "epoch  945  loss =  40.30228837947453\n",
      "epoch  946  loss =  40.30213856951352\n",
      "epoch  947  loss =  40.30198907774377\n",
      "epoch  948  loss =  40.30183990315332\n",
      "epoch  949  loss =  40.30169104473458\n",
      "epoch  950  loss =  40.301542501484136\n",
      "epoch  951  loss =  40.30139427240287\n",
      "epoch  952  loss =  40.30124635649584\n",
      "epoch  953  loss =  40.30109875277232\n",
      "epoch  954  loss =  40.300951460245756\n",
      "epoch  955  loss =  40.30080447793372\n",
      "epoch  956  loss =  40.30065780485796\n",
      "epoch  957  loss =  40.30051144004429\n",
      "epoch  958  loss =  40.3003653825226\n",
      "epoch  959  loss =  40.30021963132689\n",
      "epoch  960  loss =  40.30007418549516\n",
      "epoch  961  loss =  40.29992904406944\n",
      "epoch  962  loss =  40.29978420609576\n",
      "epoch  963  loss =  40.299639670624146\n",
      "epoch  964  loss =  40.299495436708575\n",
      "epoch  965  loss =  40.29935150340695\n",
      "epoch  966  loss =  40.29920786978111\n",
      "epoch  967  loss =  40.29906453489676\n",
      "epoch  968  loss =  40.2989214978235\n",
      "epoch  969  loss =  40.29877875763482\n",
      "epoch  970  loss =  40.298636313408004\n",
      "epoch  971  loss =  40.29849416422413\n",
      "epoch  972  loss =  40.29835230916813\n",
      "epoch  973  loss =  40.298210747328724\n",
      "epoch  974  loss =  40.29806947779832\n",
      "epoch  975  loss =  40.2979284996731\n",
      "epoch  976  loss =  40.29778781205299\n",
      "epoch  977  loss =  40.297647414041585\n",
      "epoch  978  loss =  40.297507304746176\n",
      "epoch  979  loss =  40.2973674832777\n",
      "epoch  980  loss =  40.29722794875075\n",
      "epoch  981  loss =  40.29708870028358\n",
      "epoch  982  loss =  40.29694973699797\n",
      "epoch  983  loss =  40.29681105801936\n",
      "epoch  984  loss =  40.29667266247673\n",
      "epoch  985  loss =  40.29653454950261\n",
      "epoch  986  loss =  40.296396718233076\n",
      "epoch  987  loss =  40.2962591678077\n",
      "epoch  988  loss =  40.296121897369595\n",
      "epoch  989  loss =  40.2959849060653\n",
      "epoch  990  loss =  40.29584819304484\n",
      "epoch  991  loss =  40.29571175746171\n",
      "epoch  992  loss =  40.29557559847278\n",
      "epoch  993  loss =  40.295439715238395\n",
      "epoch  994  loss =  40.295304106922224\n",
      "epoch  995  loss =  40.29516877269137\n",
      "epoch  996  loss =  40.295033711716265\n",
      "epoch  997  loss =  40.29489892317068\n",
      "epoch  998  loss =  40.29476440623173\n",
      "epoch  999  loss =  40.29463016007983\n",
      "['revolves', 'around', 'earth']\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "corpus += \"The earth revolves around the sun. The moon revolves around the earth\"\n",
    "epochs = 1000\n",
    "\n",
    "training_data = preprocessing(corpus)\n",
    "w2v = word2vec()\n",
    "\n",
    "prepare_data_for_training(training_data,w2v)\n",
    "w2v.train(epochs)\n",
    "\n",
    "print(w2v.predict(\"around\",3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
